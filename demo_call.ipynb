{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3573c3fb-9ce7-467a-b9cc-9a3d1c275824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\OneDrive\\Documentos\\llama_pipeline\\venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ssl\n",
    "import certifi\n",
    "\n",
    "ssl._create_default_https_context = lambda: ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "import asyncio\n",
    "import re\n",
    "from typing import Any\n",
    "\n",
    "from llama_index.core import Settings, Document, VectorStoreIndex\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.readers.file import PDFReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import instructor\n",
    "from instructor import Mode\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ab7b47-2489-4f13-8452-7aea186266f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 03:21:53,825 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localizacao='Rua das Palmeiras, oitenta e cinco' nivel_urgencia='alto' tipo_situacao='briga doméstica' pessoas_envolvidas='homem, mulher, criança' resumo='Homem agredindo mulher e criança em Rua das Palmeiras, oitenta e cinco.'\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "client = instructor.patch(client) \n",
    "\n",
    "class CallReport(BaseModel):\n",
    "    localizacao: str = Field(..., description=\"Local onde ocorre o incidente\")\n",
    "    nivel_urgencia: str = Field(..., description=\"Nível de urgência: baixo, médio ou alto\")\n",
    "    tipo_situacao: str = Field(..., description=\"Tipo de situação: incêndio, briga doméstica, acidente, etc.\")\n",
    "    pessoas_envolvidas: str = Field(..., description=\"Número ou descrição das pessoas envolvidas\")\n",
    "    resumo: str = Field(..., description=\"Resumo breve do que está acontecendo\")\n",
    "\n",
    "#Menos coerente, mais caótico e mais longo\n",
    "transcript = \"\"\"\n",
    "Alô, polícia? Ai, meu Deus escuta, tem um um homem aqui na rua. \n",
    "Ele tá, ele tá batendo num carro, não, espera, agora ele tá gritando com ela, com a mulher. Acho que o carro é dele, ou dela, não sei.\n",
    "É na Rua das Palmeiras, oitenta e cinco. Não, espera, eu tô no oitenta e cinco, a casa é a da esquina! Isso, a da esquina! \n",
    "Ele ele tá arroz a porta do carro, eu acho.\n",
    "A mulher tá chorando muito. Ela, ela caiu? Não, levantou. Parece machucada, mas tá escuro, não vejo direito. \n",
    "Teve um barulho agora há pouco, um estalo, tipo tipo garrafa. Foi uma garrafa? Não sei. \n",
    "Ele jogou alguma coisa, mas não vi o que era. Ele tá ele não tá normal, moça, parece sei lá.\n",
    "Por favor, tem como vir rápido? Ele Ah! Agora agora tem uma criança. Chorando. \n",
    "Antes não tinha. De onde, acho que é da casa. É o filho, eu não sei se é o filho dela.\n",
    "Meu Deus, ele ele abriu a porta. Da casa. Ele tá entrando. Não, ele tá puxando ela pra dentro! Ele puxou ela! \n",
    "Ele farinha a porta fechou. Eu ouvi a tranca? Acho que ouvi a tranca. Ai, meu Deus.\n",
    "Tem alguém lá dentro ela eu não ouço mais nada. Só a criança. Por favor, vem logo.\n",
    "\"\"\"\n",
    "\n",
    "report = client.chat.completions.create(\n",
    "    model=\"llama3.1:8B\",\n",
    "    response_model=CallReport,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Você é um analista de chamadas de emergência. Sua tarefa é extrair informações essenciais da conversa.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Extraia as seguintes informações estruturadas desta transcrição de chamada de emergência, lembre de quebrar a linha:\n",
    "\n",
    "- localizacao\n",
    "- nivel_urgencia (baixo, medio, alto)\n",
    "- tipo_situacao\n",
    "- pessoas_envolvidas\n",
    "- resumo\n",
    "\n",
    "Transcrição:\n",
    "{transcript}\n",
    "\"\"\",},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    timeout=2400,\n",
    ")\n",
    "\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
